# composer.py
import os
import re
import logging
import json
from dataclasses import dataclass
from typing import List, Dict, Any
from dotenv import load_dotenv
from openai import OpenAI

# Náº¡p biáº¿n mÃ´i trÆ°á»ng tá»« file .env
load_dotenv()

# ---------------------------
# Logging
# ---------------------------
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(name)s: %(message)s",
    handlers=[logging.StreamHandler()]
)
logger = logging.getLogger("GenoraAI.Composer")

# ---------------------------
# Data model
# ---------------------------
@dataclass
class ComposeConfig:
    model: str = "gpt-4o"
    talk_temperature: float = 0.8
    talk_max_tokens: int = 8000          # giá»›i háº¡n token cho bÃ i phÃ¡p thoáº¡i
    summary_max_words: int = 1500
    summary_clip_words: int = 300
    top_n_blocks: int = 15
    talk_target_words: int = 6000        # sá»‘ tá»« mong muá»‘n cho toÃ n bá»™ phÃ¡p thoáº¡i

# ---------------------------
# File utilities
# ---------------------------
def read_json_corpus(path: str) -> List[Dict[str, Any]]:
    abs_path = os.path.abspath(path)
    if not os.path.isfile(abs_path):
        raise FileNotFoundError(f"Corpus file not found: {abs_path}")
    with open(abs_path, "r", encoding="utf-8") as f:
        data = json.load(f)
    if not isinstance(data, list):
        raise ValueError("Corpus JSON pháº£i lÃ  danh sÃ¡ch cÃ¡c block.")
    return data

# ---------------------------
# Helpers
# ---------------------------
def count_words(text: str) -> int:
    return len(text.split())

def truncate_text(text: str, max_words: int) -> str:
    words = text.split()
    if len(words) > max_words:
        return " ".join(words[:max_words]) + " ..."
    return text

def safe_get_content(resp) -> str:
    try:
        choice = resp.choices[0]
        if hasattr(choice, "message") and hasattr(choice.message, "content"):
            return (choice.message.content or "").strip()
        return (choice["message"]["content"] or "").strip()
    except Exception:
        return ""

def clean_text(text: str) -> str:
    if not text:
        return ""
    # Loáº¡i bá» cÃ¡c kÃ½ tá»± Ä‘Ã¡nh dáº¥u format dÆ° thá»«a
    text = re.sub(r"[*#]+", "", text)
    return text.replace(":**", ":").replace("**", "").strip()

# ---------------------------
# Corpus filtering (ngá»¯ nghÄ©a cÆ¡ báº£n, Æ°u tiÃªn cá»¥m tá»« Ä‘áº§y Ä‘á»§)
# ---------------------------
def select_top_related_blocks(
    corpus_blocks: List[Dict[str, Any]],
    user_topic: str,
    top_n: int = 10,
    per_block_clip_words: int = 120
) -> List[str]:
    """
    Chá»n ra top_n block cÃ³ ngá»¯ nghÄ©a gáº§n vá»›i chá»§ Ä‘á» ngÆ°á»i dÃ¹ng.
    - Æ¯u tiÃªn khá»›p cá»¥m tá»« Ä‘áº§y Ä‘á»§ (topic_lower in text_lower).
    - Náº¿u Ã­t káº¿t quáº£, fallback: cháº¥m Ä‘iá»ƒm theo sá»‘ tá»« trÃ¹ng.
    - Cáº¯t gá»n má»—i block má»™t láº§n Ä‘á»ƒ trÃ¡nh quÃ¡ dÃ i.
    """
    if not user_topic or not user_topic.strip():
        return []

    topic_lower = user_topic.lower().strip()
    related_blocks: List[str] = []

    # BÆ°á»›c 1: Æ¯u tiÃªn block chá»©a nguyÃªn cá»¥m chá»§ Ä‘á»
    for block in corpus_blocks:
        text = (block.get("content") or "").strip()
        if not text:
            continue
        text_lower = text.lower()
        if topic_lower in text_lower:
            related_blocks.append(truncate_text(text, per_block_clip_words))

    # BÆ°á»›c 2: Náº¿u chÆ°a Ä‘á»§, fallback theo Ä‘iá»ƒm tá»« trÃ¹ng
    if len(related_blocks) < top_n:
        scored = []
        topic_words = [w for w in topic_lower.split() if w]
        for block in corpus_blocks:
            text = (block.get("content") or "").strip()
            if not text:
                continue
            text_lower = text.lower()
            score = sum(1 for w in topic_words if w in text_lower)
            if score > 0 and truncate_text(text, per_block_clip_words) not in related_blocks:
                scored.append((score, truncate_text(text, per_block_clip_words)))
        scored.sort(key=lambda x: x[0], reverse=True)

        # Bá»• sung cho Ä‘á»§ top_n
        for _, clipped in scored:
            if len(related_blocks) >= top_n:
                break
            related_blocks.append(clipped)

    # BÆ°á»›c 3: Náº¿u váº«n rá»—ng (trÆ°á»ng há»£p hiáº¿m), khÃ´ng fallback bá»«a bÃ£i Ä‘á»ƒ trÃ¡nh láº¡c Ä‘á»
    return related_blocks[:top_n]

# ---------------------------
# Prompt builder (gÃºt gá»n má»™t hÃ m duy nháº¥t)
# ---------------------------
def build_talk_prompt(key_points: str, user_topic: str = "", target_words: int = 6000) -> list:
    """
    Tráº£ vá» danh sÃ¡ch messages (system + user) Ä‘á»ƒ gá»­i vÃ o API.
    - Nháº¥n máº¡nh yÃªu cáº§u Ä‘á»™ dÃ i chi tiáº¿t theo tá»«ng pháº§n.
    - Chá»§ Ä‘á» Ä‘Æ°á»£c tá»•ng há»£p tá»« corpus vÃ  ngÆ°á»i dÃ¹ng, khÃ´ng máº·c Ä‘á»‹nh.
    """
    system_content = (
        "Báº¡n lÃ  Genora AI, trá»£ lÃ½ Pháº­t há»c. "
        "HÃ£y biÃªn soáº¡n má»™t bÃ i phÃ¡p thoáº¡i má»›i dá»±a trÃªn Ã½ chÃ­nh tá»« corpus, "
        "bÃ¡m sÃ¡t trá»ng tÃ¢m cÃ¢u há»i ngÆ°á»i dÃ¹ng, khÃ´ng sao chÃ©p nguyÃªn vÄƒn.\n\n"
        "Cáº¥u trÃºc: TiÃªu Ä‘á», Má»Ÿ bÃ i, ThÃ¢n bÃ i (10 má»¥c), Káº¿t luáº­n.\n"
        "VÄƒn phong: thuáº§n Pháº­t há»c, trang nghiÃªm, rÃµ rÃ ng, uyá»ƒn chuyá»ƒn, sÃºc tÃ­ch.\n\n"
        f"YÃªu cáº§u Ä‘á»™ dÃ i tá»•ng thá»ƒ: Ã­t nháº¥t {target_words} tá»«.\n"
        "- Má»Ÿ bÃ i: tá»‘i thiá»ƒu 150 tá»«, triá»ƒn khai sÃ¢u Ã½ nghÄ©a khá»Ÿi Ä‘áº§u.\n"
        "- Má»—i má»¥c trong ThÃ¢n bÃ i: tá»‘i thiá»ƒu 200 tá»«, phÃ¢n tÃ­ch chi tiáº¿t, cÃ³ vÃ­ dá»¥ minh há»a, "
        "trÃ­ch dáº«n kinh Ä‘iá»ƒn vÃ  liÃªn há»‡ thá»±c tiá»…n.\n"
        "- Káº¿t luáº­n: tá»‘i thiá»ƒu 300 tá»«, tá»•ng há»£p vÃ  nháº¥n máº¡nh Ã½ nghÄ©a thá»±c hÃ nh.\n\n"
        "YÃªu cáº§u trá»ng tÃ¢m: Chá»‰ triá»ƒn khai chá»§ Ä‘á» chÃ­nh Ä‘Æ°á»£c tá»•ng há»£p tá»« corpus vÃ  ngÆ°á»i dÃ¹ng, "
        "trÃ¡nh lan man sang khÃ¡i niá»‡m ngoÃ i pháº¡m vi.\n"
        "KhÃ´ng Ä‘Æ°á»£c viáº¿t máº·c Ä‘á»‹nh chá»§ Ä‘á», mÃ  pháº£i tá»•ng há»£p chá»§ Ä‘á» tá»« dá»¯ liá»‡u Ä‘áº§u vÃ o."
    )

    user_content = (
        (f"Chá»§ Ä‘á»: {user_topic}\n\n" if user_topic else "") +
        "TÃ³m táº¯t Ã½ chÃ­nh tá»« corpus (chá»‰ lÃ m Ä‘iá»ƒm tá»±a, khÃ´ng sao chÃ©p nguyÃªn vÄƒn):\n\n"
        f"{key_points}\n\n"
        "HÃ£y dá»±a trÃªn cÃ¡c Ã½ chÃ­nh nÃ y Ä‘á»ƒ biÃªn soáº¡n phÃ¡p thoáº¡i má»›i, "
        "giáº£i thÃ­ch Ä‘Ãºng trá»ng tÃ¢m, rÃµ rÃ ng, cÃ³ chiá»u sÃ¢u, vÃ  uyá»ƒn chuyá»ƒn."
    )

    return [
        {"role": "system", "content": system_content},
        {"role": "user", "content": user_content}
    ]

# ---------------------------
# Core function
# ---------------------------
def compose_dharma_talk(client: OpenAI, cfg: ComposeConfig, key_points: str, user_topic: str = "") -> str:
    messages = build_talk_prompt(key_points, user_topic, cfg.talk_target_words)
    logger.info("ğŸš€ Gá»i API duy nháº¥t má»™t láº§n Ä‘á»ƒ biÃªn soáº¡n phÃ¡p thoáº¡i...")
    try:
        resp = client.chat.completions.create(
            model=cfg.model,
            messages=messages,
            temperature=cfg.talk_temperature,
            max_tokens=cfg.talk_max_tokens
        )
        talk = safe_get_content(resp)
        return clean_text(talk or "[KhÃ´ng nháº­n Ä‘Æ°á»£c phÃ¡p thoáº¡i]")
    except Exception as e:
        logger.error(f"âŒ Lá»—i khi biÃªn soáº¡n phÃ¡p thoáº¡i: {e}")
        return "[KhÃ´ng thá»ƒ biÃªn soáº¡n phÃ¡p thoáº¡i]"

def extend_dharma_talk(client: OpenAI, cfg: ComposeConfig, last_talk: str, user_topic: str = "", target_words: int = 6000) -> str:
    system_content = (
        "Báº¡n lÃ  Genora AI, trá»£ lÃ½ Pháº­t há»c. "
        "HÃ£y má»Ÿ rá»™ng vÃ  phÃ¢n tÃ­ch sÃ¢u hÆ¡n phÃ¡p thoáº¡i sau Ä‘Ã¢y, "
        "giá»¯ nguyÃªn cáº¥u trÃºc, bá»• sung chi tiáº¿t, vÃ­ dá»¥ minh há»a, trÃ­ch dáº«n kinh Ä‘iá»ƒn, "
        f"vÃ  tÄƒng Ä‘á»™ dÃ i tá»•ng thá»ƒ lÃªn Ã­t nháº¥t {target_words} tá»«."
    )

    user_content = (
        (f"Chá»§ Ä‘á»: {user_topic}\n\n" if user_topic else "") +
        "PhÃ¡p thoáº¡i trÆ°á»›c Ä‘Ã³:\n\n" +
        last_talk
    )

    messages = [
        {"role": "system", "content": system_content},
        {"role": "user", "content": user_content}
    ]

    logger.info("ğŸš€ Má»Ÿ rá»™ng phÃ¡p thoáº¡i hiá»‡n cÃ³...")
    try:
        resp = client.chat.completions.create(
            model=cfg.model,
            messages=messages,
            temperature=cfg.talk_temperature,
            max_tokens=cfg.talk_max_tokens
        )
        extended = safe_get_content(resp)
        return clean_text(extended or "[KhÃ´ng nháº­n Ä‘Æ°á»£c ná»™i dung má»Ÿ rá»™ng]")
    except Exception as e:
        logger.error(f"âŒ Lá»—i khi má»Ÿ rá»™ng phÃ¡p thoáº¡i: {e}")
        return "[KhÃ´ng thá»ƒ má»Ÿ rá»™ng phÃ¡p thoáº¡i]"

# ---------------------------
# High-level workflow
# ---------------------------
def run_composition(api_key: str, model: str = "gpt-4o", user_topic: str = "") -> Dict[str, str]:
    cfg = ComposeConfig(model=model)
    client = OpenAI(api_key=api_key)

    corpus_file = os.path.join("data", "training_corpus_clustered.json")
    logger.info(f"ğŸ“‚ Äang táº£i file corpus JSON: {corpus_file}")

    try:
        corpus_blocks = read_json_corpus(corpus_file)
    except Exception as e:
        logger.error(f"âŒ Lá»—i khi Ä‘á»c corpus JSON: {e}")
        return {"summary": "", "talk": ""}

    if not corpus_blocks:
        logger.warning("âš ï¸ Corpus rá»—ng, khÃ´ng thá»ƒ biÃªn soáº¡n phÃ¡p thoáº¡i.")
        return {"summary": "", "talk": ""}

    related_blocks = select_top_related_blocks(
        corpus_blocks,
        user_topic,
        top_n=cfg.top_n_blocks,
        per_block_clip_words=cfg.summary_clip_words
    )
    if not related_blocks:
        logger.warning(f"âš ï¸ KhÃ´ng tÃ¬m tháº¥y Ä‘oáº¡n nÃ o liÃªn quan Ä‘áº¿n chá»§ Ä‘á» '{user_topic}'.")
        return {"summary": "", "talk": ""}

    summary_raw = "\n- " + "\n- ".join(related_blocks)
    summary = truncate_text(summary_raw, cfg.summary_max_words)

    total_blocks = len(corpus_blocks)
    related_count = len(related_blocks)
    percent = (related_count / total_blocks * 100) if total_blocks > 0 else 0

    logger.info(
        f"ğŸ“Š Tá»•ng sá»‘ block trong corpus: {total_blocks}. "
        f"Sá»‘ block liÃªn quan Ä‘áº¿n '{user_topic}': {related_count} "
        f"({percent:.2f}% trÃªn tá»•ng). "
        f"(ÄÃ£ chá»n tá»‘i Ä‘a {cfg.top_n_blocks} block Ä‘á»ƒ tÃ³m táº¯t)"
    )
    logger.info(
        f"âœ… TÃ³m táº¯t ná»™i bá»™ gá»“m {len(summary.split())} tá»«. "
        f"(Má»—i block Ä‘Ã£ cáº¯t tá»‘i Ä‘a {cfg.summary_clip_words} tá»«, "
        f"tá»•ng thá»ƒ summary cáº¯t tá»‘i Ä‘a {cfg.summary_max_words} tá»«)"
    )

    try:
        talk = compose_dharma_talk(client, cfg, summary, user_topic)
        logger.info("âœ… HoÃ n táº¥t biÃªn soáº¡n phÃ¡p thoáº¡i (chá»‰ má»™t phiÃªn báº£n cuá»‘i cÃ¹ng Ä‘Æ°á»£c xuáº¥t ra).")
    except Exception as e:
        logger.error(f"âŒ Lá»—i khi biÃªn soáº¡n phÃ¡p thoáº¡i: {e}")
        return {"summary": summary, "talk": ""}

    logger.info(
        "ğŸ“Š Thá»‘ng kÃª cuá»‘i cÃ¹ng:\n"
        f"- Chá»§ Ä‘á»: {user_topic}\n"
        f"- Summary: {len(summary.split())} tá»«\n"
        f"- Talk: {len(talk.split())} tá»«\n"
        "ğŸ‘‰ Chá»‰ má»™t báº£n phÃ¡p thoáº¡i duy nháº¥t Ä‘Æ°á»£c xuáº¥t ra sau toÃ n bá»™ quÃ¡ trÃ¬nh."
    )

    return {"summary": summary, "talk": talk}

# ---------------------------
# CLI usage
# ---------------------------
last_talk = None  # lÆ°u phÃ¡p thoáº¡i gáº§n nháº¥t

if __name__ == "__main__":
    import datetime, time
    api_key_env = os.getenv("OPENAI_API_KEY")
    if not api_key_env:
        raise RuntimeError("OPENAI_API_KEY chÆ°a Ä‘Æ°á»£c cáº¥u hÃ¬nh trong mÃ´i trÆ°á»ng.")

    client = OpenAI(api_key=api_key_env)  # táº¡o client má»™t láº§n
    cfg = ComposeConfig()

    while True:
        user_command = input("Nháº­p lá»‡nh (vÃ­ dá»¥: 'compose <chá»§ Ä‘á»>' hoáº·c 'compose thÃªm', 'exit' Ä‘á»ƒ thoÃ¡t): ").strip()
        if user_command == "exit":
            break

        start_time = time.time()
        start_stamp = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        logger.info(f"ğŸš€ Báº¯t Ä‘áº§u xá»­ lÃ½ vÃ o lÃºc: {start_stamp}")

        if user_command.startswith("compose thÃªm"):
            if last_talk:
                result_talk = extend_dharma_talk(client=client,
                                                 cfg=cfg,
                                                 last_talk=last_talk,
                                                 user_topic="",
                                                 target_words=6000)
                print("\n--- PHÃP THOáº I Má» Rá»˜NG ---\n")
                print(result_talk)
                last_talk = result_talk
            else:
                logger.warning("âš ï¸ KhÃ´ng cÃ³ phÃ¡p thoáº¡i trÆ°á»›c Ä‘Ã³ Ä‘á»ƒ má»Ÿ rá»™ng.")
        elif user_command.startswith("compose "):
            user_topic = user_command.replace("compose", "").strip()
            result = run_composition(api_key=api_key_env, user_topic=user_topic)
            print("\n--- TÃ“M Táº®T Ã CHÃNH THEO CHá»¦ Äá»€ ---\n")
            print(result["summary"])
            print("\n--- BÃ€I PHÃP THOáº I ---\n")
            print(result["talk"])
            last_talk = result["talk"]
        else:
            logger.warning("âš ï¸ Lá»‡nh khÃ´ng há»£p lá»‡. HÃ£y dÃ¹ng 'compose <chá»§ Ä‘á»>' hoáº·c 'compose thÃªm'.")

        end_time = time.time()
        end_stamp = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        duration = end_time - start_time
        logger.info(f"âœ… HoÃ n táº¥t vÃ o lÃºc: {end_stamp}, tá»•ng thá»i gian xá»­ lÃ½: {duration:.2f} giÃ¢y")